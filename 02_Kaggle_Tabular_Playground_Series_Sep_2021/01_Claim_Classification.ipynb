{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tabular Playground Series - Sep 2021\n",
    "\n",
    "[https://www.kaggle.com/c/tabular-playground-series-sep-2021/overview](https://www.kaggle.com/c/tabular-playground-series-sep-2021/overview)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "N_SPLITS = 5\n",
    "N_ESTIMATORS = 25001\n",
    "EARLY_STOPPING_ROUNDS = 3048 # very important, well protects against overfitting\n",
    "VERBOSE = 1000 # faster and more clearly\n",
    "SEED = 42"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test  = pd.read_csv('data/test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "train.set_index('id', inplace=True)\n",
    "test.set_index('id', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "features = test.columns.to_list()\n",
    "TARGET = 'claim'\n",
    "\n",
    "target = train[TARGET].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Idea taken from https://www.kaggle.com/realtimshady/single-simple-lightgbm Missing feature values are replaced depending on the type of distribution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "train['n_missing'] = train[features].isna().sum(axis=1)\n",
    "train['min'] = train[features].min(axis=1)\n",
    "train['sem']= train[features].sem(axis=1)\n",
    "train['quantile'] = train[features].quantile(axis = 1)\n",
    "\n",
    "test['n_missing'] = test[features].isna().sum(axis=1)\n",
    "test['min'] = test[features].min(axis=1)\n",
    "test['sem']= test[features].sem(axis=1)\n",
    "test['quantile'] = test[features].quantile(axis=1)\n",
    "\n",
    "features += ['n_missing','min','sem','quantile']\n",
    "n_missing = train['n_missing'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', StandardScaler()) #StandardScaler RobustScaler\n",
    "])\n",
    "train[features] = pipeline.fit_transform(train[features])\n",
    "test[features] = pipeline.transform(test[features])\n",
    "\n",
    "train.shape, test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((957919, 123), (493474, 122))"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['claim']\n",
    "X_valid = valid_df[features]\n",
    "y_valid = valid_df['claim']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, min_samples_split=1000)\n",
    "rf.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "y, y_pred, y_pred_prob = y_train, rf.predict(X_train), rf.predict_proba(X_train)[:,1]\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Train AUC: {roc_auc_score(y, y_pred_prob)}\")\n",
    "\n",
    "y, y_pred, y_pred_prob = y_valid, rf.predict(X_valid), rf.predict_proba(X_valid)[:,1]\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Valid AUC: {roc_auc_score(y, y_pred_prob)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    384251\n",
      "           1       1.00      0.99      1.00    382084\n",
      "\n",
      "    accuracy                           1.00    766335\n",
      "   macro avg       1.00      1.00      1.00    766335\n",
      "weighted avg       1.00      1.00      1.00    766335\n",
      "\n",
      "Train AUC: 0.9999774968571538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74     96153\n",
      "           1       0.72      0.89      0.79     95431\n",
      "\n",
      "    accuracy                           0.77    191584\n",
      "   macro avg       0.79      0.77      0.77    191584\n",
      "weighted avg       0.79      0.77      0.77    191584\n",
      "\n",
      "Valid AUC: 0.7975208448603008\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.69      0.77    384251\n",
    "           1       0.74      0.90      0.81    382084\n",
    "\n",
    "    accuracy                           0.79    766335\n",
    "   macro avg       0.81      0.79      0.79    766335\n",
    "weighted avg       0.81      0.79      0.79    766335\n",
    "\n",
    "Train AUC: 0.9608403844858073\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.65      0.74     96153\n",
    "           1       0.72      0.90      0.80     95431\n",
    "\n",
    "    accuracy                           0.77    191584\n",
    "   macro avg       0.79      0.77      0.77    191584\n",
    "weighted avg       0.79      0.77      0.77    191584\n",
    "\n",
    "Valid AUC: 0.8013681618511015"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77760899d304acafbb398cabb388ddb19ee6456efe17831dc3c4e819d339ff7c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('tfGpuEnv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}